---
title: "Prediction Assignment Writeup"
author: "Mick Sheahan"
date: "3/22/2018"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

Peer-graded Assignment: Prediction Assignment Writeup

```{r message=FALSE, warning=FALSE}
## Load prediction and plotting libraries
library(caret)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
library(corrplot)
library(knitr)
```

### Introduction
One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.  
In this project, use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants.  
The goal of the project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set.

This paper refers to the WLE dataset:  

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.   

Read more: http://groupware.les.inf.puc-rio.br/har#weight_lifting_exercises#ixzz5AUaLfzAn

##### Load and Examine Data
```{r load data}
# Load data
trainURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
traincsv <- "./data/WLE-trainingset.csv"
testcsv  <- "./data/WLE-testingset.csv"
if (!file.exists("./data")) {
  dir.create("./data")
}
if (!file.exists(traincsv)) {
  download.file(trainURL, destfile=traincsv, method="curl")
}
if (!file.exists(testcsv)) {
  download.file(testURL, destfile=testcsv, method="curl")
}
# Read data
train <- read.csv("./data/WLE-trainingset.csv", na.strings = c("NA", "", "#DIV0!"))
test <- read.csv("./data/WLE-testingset.csv", na.strings = c("NA", "", "#DIV0!"))
# Examine data
dim(train)
dim(test)
```

##### Clean Data     
Remove all columns that contains NA, identification variables, and other variables containing values not related (e.g. timestamps)   

```{r clean data}
# Remove identification variables
train <- train[, -(1:7)]
test <- test[, -(1:7)]
# Remove variables containing NA
train <- train[, colSums(is.na(train)) == 0] 
test <- test[, colSums(is.na(test)) == 0] 
dim(train)
dim(test)
```

The final training data set is cleaned and contains 19622 observations and 53 variables.   
The final testing data set is cleaned and contains 20 observations and 53 variables.     

##### Cross Validation   

Using the training data set the data is partitioned into 70% training and 30% validation. This will be used for Cross Validation.  

```{r Cross Validation}
set.seed(2609)
inTrain <- createDataPartition(train$classe, p=0.70, list=F)
trainData <- train[inTrain,]
testData <- train[-inTrain,]
dim(trainData)
dim(testData)
```

### Choosing the model    
3 models will be tested; Random Forest, Boosting and Decision Tree.   
For each one, a confusion matrix will be shown to visualise the accuracy and out of sample error.   
The model with the highest accuracy will be used for the 20 test cases.   

##### Random Forest model  

```{r cv model}
set.seed(2609)
model <- trainControl(method = "repeatedcv", 5, repeats = 1)
RF <- train(classe ~ ., data = trainData, method = "rf", trControl = model, verbose = FALSE)
RF
# Prediction with Random Forest model
pred_RF <- predict(RF, testData)
confusionMatrix(testData$classe, pred_RF)
# Accuracy of Random Forest model
accRF <- postResample(pred_RF, testData$classe)
errorRF <- 1 - as.numeric(confusionMatrix(testData$classe, pred_RF)$overall[1])
accRF
errorRF
```

##### Boosting model

```{r boosting}
set.seed(2609)
GBM  <- train(classe ~ ., data = trainData, method = "gbm",
                    trControl = model, verbose = FALSE)
GBM
# Prediction with Boosting model
pred_GBM <- predict(GBM, testData)
confusionMatrix(testData$classe, pred_GBM)
# Accuracy of Boosting model
accGBM <- postResample(pred_GBM, testData$classe)
errorGBM <- 1 - as.numeric(confusionMatrix(testData$classe, pred_GBM)$overall[1])
accGBM
errorGBM
```

##### Decision Tree model

```{r dt model}
set.seed(2609)
DT <- rpart(classe ~ ., data = trainData, method = "class", control = rpart.control(method = "repeatedcv", number = 5))
DT
# Prediction with Decision Tree model
pred_DT <- predict(DT, testData, type = "class")
confusionMatrix(pred_DT, testData$classe)
# Accuracy of Decision Tree model
accDT <- postResample(pred_DT, testData$classe)
errorDT <- 1 - as.numeric(confusionMatrix(testData$classe, pred_DT)$overall[1])
accDT
errorDT
```

### Result    

The Random Forest model had the highest accuracy and so will be used on the 20 test cases.   

### Prediction of 20 test cases   

```{r predict 20 test cases}
cases <- predict(RF, test)
cases
```

### Appendix of Figures

```{r plot 1 RF}
plot(RF, main = "Random Forest Model")
```

```{r plot 2 GBM}
plot(GBM, main = "Boosting Model")
```

```{r plot 3 DT}
fancyRpartPlot(DT, sub = "Decision Tree Model")
```


